{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gTfdRM5dFYD",
        "outputId": "1a684fc9-6024-486b-cbec-8086673ef7d0"
      },
      "source": [
        "!git clone https://github.com/IBM/deep-learning-language-model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-learning-language-model'...\n",
            "remote: Enumerating objects: 395, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 395 (delta 0), reused 0 (delta 0), pack-reused 393\u001b[K\n",
            "Receiving objects: 100% (395/395), 37.74 MiB | 24.97 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-TFPy1fdjdK"
      },
      "source": [
        "from __future__ import print_function\n",
        "import json\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFkSck_1eUcb",
        "outputId": "602aa4ba-23cd-47bc-c2d2-9c997247cd86"
      },
      "source": [
        "path = 'deep-learning-language-model/yelp_100_3.txt'\n",
        "text = open(path).read().lower()\n",
        "print('corpus length:', len(text))\n",
        "char_indices = json.loads(open('deep-learning-language-model/char_indices.txt').read())\n",
        "indices_char = json.loads(open('deep-learning-language-model/indices_char.txt').read())\n",
        "chars = sorted(char_indices.keys())\n",
        "print(indices_char)\n",
        "#chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "#char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "#indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 256\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "print('Vectorization...')\n",
        "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "\n",
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(1024, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
        "model.add(LSTM(512, return_sequences=False))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = Adam(lr=0.002)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "model.load_weights(\"deep-learning-language-model/transfer_weights\")\n",
        "\n",
        "def sample(preds, temperature=.6):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "# train the model, output generated text after each iteration\n",
        "for iteration in range(1, 60):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    x = np.zeros((1, maxlen, len(chars)))\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    \n",
        "    model.fit(X, y, batch_size=128, epochs=1)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    #start_index = char_indices[\"{\"]\n",
        "\n",
        "    for diversity in [0.2, 0.4, 0.6, 0.8]:\n",
        "        print()\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "        for i in range(400):\n",
        "            x = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            #print(next_index)\n",
        "            #print (indices_char)\n",
        "            next_char = indices_char[str(next_index)]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "model.save_weights(\"transfer_weights\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 71250\n",
            "{'0': '\\n', '1': ' ', '2': '!', '3': '\"', '4': '#', '5': '$', '6': '%', '7': '&', '8': \"'\", '9': '(', '10': ')', '11': '*', '12': '+', '13': ',', '14': '-', '15': '.', '16': '/', '17': '0', '18': '1', '19': '2', '20': '3', '21': '4', '22': '5', '23': '6', '24': '7', '25': '8', '26': '9', '27': ':', '28': ';', '29': '=', '30': '?', '31': '[', '32': ']', '33': 'a', '34': 'b', '35': 'c', '36': 'd', '37': 'e', '38': 'f', '39': 'g', '40': 'h', '41': 'i', '42': 'j', '43': 'k', '44': 'l', '45': 'm', '46': 'n', '47': 'o', '48': 'p', '49': 'q', '50': 'r', '51': 's', '52': 't', '53': 'u', '54': 'v', '55': 'w', '56': 'x', '57': 'y', '58': 'z', '59': '{', '60': '}'}\n",
            "total chars: 61\n",
            "nb sequences: 23665\n",
            "Vectorization...\n",
            "Build model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "185/185 [==============================] - 5041s 27s/step - loss: 1.4968\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"e this place, or at least like it.  we walked out of there terribly disappointed, i doubt we'll go back.}{this is a nothing but pies place...so i was expecting a little bit more oomph...\n",
            "\n",
            "dispointing small selection of pie by the slices...also you gotta pu\"\n",
            "e this place, or at least like it.  we walked out of there terribly disappointed, i doubt we'll go back.}{this is a nothing but pies place...so i was expecting a little bit more oomph...\n",
            "\n",
            "dispointing small selection of pie by the slices...also you gotta pup and the service is no the compery to spe is a little shopp of the salad, and i have to compery to seated a need a bit of meal for me some cheeses of the compery chicken was a bit of perfect for me hearthele for delicious are or meal with out the cook torato salad.  i would be back and salad and the service was so it was awayone.  i have been at the porking and the patio soon.  it's a bit of perf\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"e this place, or at least like it.  we walked out of there terribly disappointed, i doubt we'll go back.}{this is a nothing but pies place...so i was expecting a little bit more oomph...\n",
            "\n",
            "dispointing small selection of pie by the slices...also you gotta pu\"\n",
            "e this place, or at least like it.  we walked out of there terribly disappointed, i doubt we'll go back.}{this is a nothing but pies place...so i was expecting a little bit more oomph...\n",
            "\n",
            "dispointing small selection of pie by the slices...also you gotta pup to order there list aid to semperately definitely complained a little soup bowt or no salad.  i read a bit of combo and i tas a be a bit are served that the compery cours after the food and some definitely for a cheese of the food and the portious are patio seeped to the were so som the cook a bar came every the salad.  i wish a they were so the salad was good.  i would i and a beener with a she\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"e this place, or at least like it.  we walked out of there terribly disappointed, i doubt we'll go back.}{this is a nothing but pies place...so i was expecting a little bit more oomph...\n",
            "\n",
            "dispointing small selection of pie by the slices...also you gotta pu\"\n",
            "e this place, or at least like it.  we walked out of there terribly disappointed, i doubt we'll go back.}{this is a nothing but pies place...so i was expecting a little bit more oomph...\n",
            "\n",
            "dispointing small selection of pie by the slices...also you gotta pupked cook ride arearized carnet sormed list order and was pretty good... like the place for the service was to it would resure.  i could remember ne soup really cooked and the best pie partake of can't be peep care asters aithe food is a fremint stopping onerow with our tacking and i was their supprinted and some more salad.  it's not see with they come but the service is that it is so the tained \n",
            "\n",
            "----- diversity: 0.8\n",
            "----- Generating with seed: \"e this place, or at least like it.  we walked out of there terribly disappointed, i doubt we'll go back.}{this is a nothing but pies place...so i was expecting a little bit more oomph...\n",
            "\n",
            "dispointing small selection of pie by the slices...also you gotta pu\"\n",
            "e this place, or at least like it.  we walked out of there terribly disappointed, i doubt we'll go back.}{this is a nothing but pies place...so i was expecting a little bit more oomph...\n",
            "\n",
            "dispointing small selection of pie by the slices...also you gotta pulled bit pia chacked meat right and everything it to my fresh, but the food was suria and the more caperian the mell. the place, are presty zeasone of the charring for ence.\n",
            " in the service was the sit eef like thai ovenome....oin cames and have been then it was awayone of it would be couved that i love the selped with somporation. i'd uninately dees and defenotely at the boytle with place. the ir\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "185/185 [==============================] - 5085s 27s/step - loss: 1.0459\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"m has was way better.  if you go here.... order a burger.  they are big, juicy and super duper good.  it's also super duper messy.  it's a \"fork and knife\" type of burger. \n",
            "\n",
            "their bloody mary is pretty good... a little too tomato-y.... needed more seasonin\"\n",
            "m has was way better.  if you go here.... order a burger.  they are big, juicy and super duper good.  it's also super duper messy.  it's a \"fork and knife\" type of burger. \n",
            "\n",
            "their bloody mary is pretty good... a little too tomato-y.... needed more seasoning of my was got the blabbend than the best pista was good. i don't thing that is that the bonther for moss of the coffee serve"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "r was potato for a biers and difen anout the best it wasn't and shoppen and the corner of that is a girling that that is that the staff with cashes and the borther and she then the best it wasn't that the best pista was got the best past on the menu and she is a great place\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"m has was way better.  if you go here.... order a burger.  they are big, juicy and super duper good.  it's also super duper messy.  it's a \"fork and knife\" type of burger. \n",
            "\n",
            "their bloody mary is pretty good... a little too tomato-y.... needed more seasonin\"\n",
            "m has was way better.  if you go here.... order a burger.  they are big, juicy and super duper good.  it's also super duper messy.  it's a \"fork and knife\" type of burger. \n",
            "\n",
            "their bloody mary is pretty good... a little too tomato-y.... needed more seasoning that when i saided tort out the change that is a great staff.\n",
            "\n",
            "the salad and was so my friends and the most of the copped food coffee of pretis souss of peryonia and she was going to get the best past one of the strained had a but in back.  i readly did not seem and i was darg. the salad then i had a bit and served the place is no my crandlers and the best it is a good light atarle of that is to\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"m has was way better.  if you go here.... order a burger.  they are big, juicy and super duper good.  it's also super duper messy.  it's a \"fork and knife\" type of burger. \n",
            "\n",
            "their bloody mary is pretty good... a little too tomato-y.... needed more seasonin\"\n",
            "m has was way better.  if you go here.... order a burger.  they are big, juicy and super duper good.  it's also super duper messy.  it's a \"fork and knife\" type of burger. \n",
            "\n",
            "their bloody mary is pretty good... a little too tomato-y.... needed more seasoning so i as topting that the kquest of the food as the coster and the gring that is a greated in the brusscot as worth dish was very drinks and the casual blead of that was firited and shoppen mine plate to sle and drinks and everyone that the sit is got thene was a bit of cozbor about town of every was good.  i readly good. i don't thing to get a sure white was green and carnet boos....one thing we\n",
            "\n",
            "----- diversity: 0.8\n",
            "----- Generating with seed: \"m has was way better.  if you go here.... order a burger.  they are big, juicy and super duper good.  it's also super duper messy.  it's a \"fork and knife\" type of burger. \n",
            "\n",
            "their bloody mary is pretty good... a little too tomato-y.... needed more seasonin\"\n",
            "m has was way better.  if you go here.... order a burger.  they are big, juicy and super duper good.  it's also super duper messy.  it's a \"fork and knife\" type of burger. \n",
            "\n",
            "their bloody mary is pretty good... a little too tomato-y.... needed more seasoning and the dishes that not the but that it is the mesued point and sardation.\n",
            "\n",
            "we will we wasne restaurant food.  i can't do a few the other cringe of many red cheese in the burgers and then it to stals just liked thai castem dried thanks heart hed for for calioss but i tas a bit of burgers mide the castua cheff... i was avouade the strained cricken and tasty, sauce. the corterion. the bnooded towe\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "185/185 [==============================] - 5061s 27s/step - loss: 0.8124\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"n't go wrong with a meal from flemings. they also have a great happy hour.}{ok, first i broke my promise to myself and went here again, i figured by now things have got to be better. i ordered something that i wouldn't care if it was cold, french toast. ok\"\n",
            "n't go wrong with a meal from flemings. they also have a great happy hour.}{ok, first i broke my promise to myself and went here again, i figured by now things have got to be better. i ordered something that i wouldn't care if it was cold, french toast. okey mext on it was great!}{i was great!}{i was great!}{i was great!}{of pluce for the bottood the concert in the mood and i sandwich carner back and the bottle of salad.  i would be town the service was completely bottle the best say we were coffee food, but the worth stuffed bottles, but it's not sure the but in a try morn reliming the chicken was great!}{i was great!}{i was gream!}{one of the bes\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"n't go wrong with a meal from flemings. they also have a great happy hour.}{ok, first i broke my promise to myself and went here again, i figured by now things have got to be better. i ordered something that i wouldn't care if it was cold, french toast. ok\"\n",
            "n't go wrong with a meal from flemings. they also have a great happy hour.}{ok, first i broke my promise to myself and went here again, i figured by now things have got to be better. i ordered something that i wouldn't care if it was cold, french toast. okey the guy  the but it was great!}{i was great!}{i really like the concert to stuffer heart selection, but the bottor in the month time mare there was all while the food was colled to give the food as well, but the but for the stuff time ther best start.}{the pork sausage there was sublen with the best say i was great!}{i got a breakfast nucct. my house and we giff the food was gond regunder and t\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"n't go wrong with a meal from flemings. they also have a great happy hour.}{ok, first i broke my promise to myself and went here again, i figured by now things have got to be better. i ordered something that i wouldn't care if it was cold, french toast. ok\"\n",
            "n't go wrong with a meal from flemings. they also have a great happy hour.}{ok, first i broke my promise to myself and went here again, i figured by now things have got to be better. i ordered something that i wouldn't care if it was cold, french toast. okey, i tasted, i loce to stuple but you can tho the went time to get my lunch and hot smoke in a day was salad.  i got not in non a friday.  the case was sorn food, but the bottood there were some cooked to get it line when the borther.  the ghing the coffee cool and there and the tasted mext and strowge to gin bat bry on our server who the concert of ited to git was very place? for least it wouldn\n",
            "\n",
            "----- diversity: 0.8\n",
            "----- Generating with seed: \"n't go wrong with a meal from flemings. they also have a great happy hour.}{ok, first i broke my promise to myself and went here again, i figured by now things have got to be better. i ordered something that i wouldn't care if it was cold, french toast. ok\"\n",
            "n't go wrong with a meal from flemings. they also have a great happy hour.}{ok, first i broke my promise to myself and went here again, i figured by now things have got to be better. i ordered something that i wouldn't care if it was cold, french toast. okey like the who is good.  i got not smont the only of it's not light on it was gond, they difference fus breakfast/\n",
            "\n",
            "                   which i think it to as been. the orders spot in, and i love them compored at left op like the checry, but it was relling of spring, but for a like plais, but the butter than now the outsill and the ones bet sour waitress and the one of them sour not but bows of pa\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "185/185 [==============================] - 4974s 27s/step - loss: 0.6294\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"k; people coming in for happy hour (jeans and nice shirts); and people just in off the street (shorts, casual shirts, even hats). i really liked this ambiance, because it doesn't make it too stuffy and turn people \"off\" of this locally grown, organic resta\"\n",
            "k; people coming in for happy hour (jeans and nice shirts); and people just in off the street (shorts, casual shirts, even hats). i really liked this ambiance, because it doesn't make it too stuffy and turn people \"off\" of this locally grown, organic restaurant with conerelian, but awally a good pasty, cheese, be a good pattion, and to fined to my coangrels and the food was weined a nice for the mood at the booth.  i don't think it's a bit spicy compleint for the mood to stuffed heart see ed the other to the amme. their head giver the best pay i hon a higkend's carnet as a good place for the orders the food and to the took time.  he whone their hea\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"k; people coming in for happy hour (jeans and nice shirts); and people just in off the street (shorts, casual shirts, even hats). i really liked this ambiance, because it doesn't make it too stuffy and turn people \"off\" of this locally grown, organic resta\"\n",
            "k; people coming in for happy hour (jeans and nice shirts); and people just in off the street (shorts, casual shirts, even hats). i really liked this ambiance, because it doesn't make it too stuffy and turn people \"off\" of this locally grown, organic restaurant with comerearing, but he was our the food as the boythere and the booth.  they are nead by night we ordered one of the restaurant with corneration ene at the boy new cook day niget a few the ingo arsounctuace.  your tables icristeak--\n",
            "\n",
            "am into the spreing and the sauce.  i've had been agreed the salad great sitsing out our monuts, we did dot real deed the salad day was good. it was going to \n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"k; people coming in for happy hour (jeans and nice shirts); and people just in off the street (shorts, casual shirts, even hats). i really liked this ambiance, because it doesn't make it too stuffy and turn people \"off\" of this locally grown, organic resta\"\n",
            "k; people coming in for happy hour (jeans and nice shirts); and people just in off the street (shorts, casual shirts, even hats). i really liked this ambiance, because it doesn't make it too stuffy and turn people \"off\" of this locally grown, organic restaurant with the salfed a gere at bemoration. the counter was smonting and had the best phener agoun to tasty, and to me...all who had oy the botter on a fan brunched and to the took tite.  they have had it's a bit conside.  ay i'm keeat beer fart the best restaurant with the sarm the cheese to salad nead a keep better picky with dinner about did tot sure the and takes for the when i have a too hone\n",
            "\n",
            "----- diversity: 0.8\n",
            "----- Generating with seed: \"k; people coming in for happy hour (jeans and nice shirts); and people just in off the street (shorts, casual shirts, even hats). i really liked this ambiance, because it doesn't make it too stuffy and turn people \"off\" of this locally grown, organic resta\"\n",
            "k; people coming in for happy hour (jeans and nice shirts); and people just in off the street (shorts, casual shirts, even hats). i really liked this ambiance, because it doesn't make it too stuffy and turn people \"off\" of this locally grown, organic restaurant was their asten hings to music out on a sandwich was \"comporedions the best pay so it's a givinite (head of side.  i thought the heart delest to salatt. the dispecation. if you and they good the mix people's like.  the oldiods to the good tith and delicious.  our vegrees food.}{i read for our in the morning free is my rita and another con spot to mothough for the bouturd. and the coon tastic\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            " 75/185 [===========>..................] - ETA: 49:10 - loss: 0.4308"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}